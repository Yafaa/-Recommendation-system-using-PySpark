# -*- coding: utf-8 -*-
"""Projet Big Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ktjtFf6vLGjMrerKCVmvecIYO3BQZVQT

# Big Data Project 
**Mohamed Mbarek** \
**Yafaa Ben Tili** \
3e Info C

Als Recommender System Pyspark Lab
Introduction
In this Project, we will implement a  recommendation system using ALS in Spark programming environment. \
Spark's machine learning library ml comes packaged with a very efficient implementation of the ALS algorithm that we looked at in the previous lesson. The lab will require you to put into practice your Spark programming skills for creating and manipulating PySpark DataFrames. We will go through a step-by-step process into developing a movie recommendation system using ALS and PySpark using the MovieLens dataset that we used in a previous lab.

**Part 1 : install all the modules**
"""

# innstall java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# install spark (change the version number if needed)
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz

# unzip the spark file to the current folder
!tar xf spark-3.0.0-bin-hadoop3.2.tgz

# set your spark folder to your system path environment. 
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"


# install findspark using pip
!pip install -q findspark

!pip install pyspark

import pyspark
sc = pyspark.SparkContext(appName="yourAppName")

print(sc)

from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()
# Test the spark
df = spark.createDataFrame([{"hello": "world"} for x in range(1000)])
df.show(3, False)

df.show(10, False)

"""**Part 2 :Exploratory Data Analysis (EDA) using Pyspark**"""

# Get data
ratings = spark.read.option("header", "true").csv("ratings.csv")
ratings.show(5)

ratings.printSchema()

movies = spark.read.option("header", "true").csv("movies.csv")
movies.show(5)

from pyspark.sql.functions import *

most_popular = ratings\
.groupBy("movieId")\
.agg(count("userId"))\
.withColumnRenamed("count(userId)", "num_ratings")\
.sort(desc("num_ratings"))

most_popular.show(15)

most_popular_movies = most_popular.join(movies, most_popular.movieId == movies.movieId)
most_popular_movies.show(20, truncate=False)

top_rated = ratings\
.groupBy("movieId")\
.agg(avg(col("rating")))\
.withColumnRenamed("avg(rating)", "avg_rating")\
.sort(desc("avg_rating"))

top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId)
top_rated_movies.show(15)

top_rated = ratings\
.groupBy("movieId")\
.agg(count("userId"), avg(col("rating")))\
.withColumnRenamed("count(userId)", "num_ratings")\
.withColumnRenamed("avg(rating)", "avg_rating")

top_rated_movies = top_rated.join(movies, top_rated.movieId == movies.movieId).sort(desc("avg_rating"), desc("num_ratings"))
top_rated_movies.show(15)

# Calculate average, minimum, and maximum of num_ratings
top_rated_movies.select([mean('num_ratings'), min('num_ratings'), max('num_ratings')]).show(1)

"""**Part 3 : Machine learning and Recommender System**"""

ratings = spark.read.option("inferSchema",True).option("header",True).csv("ratings.csv")

ratings.show(5)

from pyspark.ml.recommendation import ALS
als = ALS(maxIter=10, regParam=0.5, userCol="userId", 
                      itemCol = "movieId", ratingCol =    "rating", coldStartStrategy = "drop")
train, test = ratings.randomSplit([0.8, 0.2])

#Training the Model
alsModel = als.fit(train)
#Generating Predictions
prediction = alsModel.transform(test)
prediction.show(10)

from pyspark.ml.evaluation import RegressionEvaluator
evaluator = RegressionEvaluator(metricName="mse", labelCol="rating",  predictionCol="prediction")
mse = evaluator.evaluate(prediction)
print(mse)

recommended_movie_df = alsModel.recommendForAllUsers(3)
recommended_movie_df.show(10, False)

recommended_movie_df = alsModel.recommendForAllUsers(5)
recommended_movie_df.show(10, False)

